\chapter{Lie Groups and Lie Algebras} \thispagestyle{empty}

In this chapter, we introduce the notion of \textit{Lie groups} via representation theory, and we describe the local properties employing the concept of \textit{Lie algebras}.

\section{Definitions and Main Properties}

Let $\G$ be a continuous group, whose elements $A(\alpha)$ are expressed as a function of a set of continuous real-valued\footnote{In fact, if $\alpha \in \C$, then it is enough to consider $\alpha = \beta + \imath \gamma$ for $\beta, \, \gamma \in \R$. } parameters $\{\alpha \}_{\alpha \in \Delta} = \{(\alpha_1, \, \alpha_2, \, \dots, \, \alpha_k)\}_{\alpha \in \Delta}$. The parameters are chosen in such a way that
\begin{equation*} A(0, \, \dots, \, 0) = e \end{equation*}
is the identity element of $\G$. 

\begin{definition}[Lie Group] \index{Lie group}A \textit{Lie group} $\G$ is a continuous group, of parameter $\alpha$, satisfying the following properties: \mbox{}
\begin{enumerate}[label=\textbf{(\alph*)}]
\item \textbf{\scshape Closure.} For every $\alpha$ and $\beta$ it turns out that
\begin{equation*} A(\alpha) A(\beta) = A(\gamma), \end{equation*}
where $\gamma = f(\alpha, \, \beta)$ and $f$ is a differentiable function with respect to both variables such that $f(\gamma, \, 0) = \gamma$ and $f(0, \, \gamma) = \gamma$.
\item \textbf{\scshape Inverse.} For every $\alpha$ it turns out that
\begin{equation*} A(\alpha)^{-1} = A(\alpha^\prime), \end{equation*}
where $\alpha^\prime$ is a differentiable function of $\alpha$.
\item \textbf{\scshape Associativity.} For every $\alpha, \, \beta$ and $\gamma$ it turns out that
\begin{equation*} A(\alpha) \left( A(\beta) A(\gamma) \right) = \left( A(\alpha) A(\beta) \right) A(\gamma), \end{equation*}
\end{enumerate}
We say that the group has dimension $r$, since $\alpha$ is a $r$-dimensional vector.
\end{definition}


\begin{remark}Let $\G$ be a Lie group. The associative property immediately implies that
\begin{equation*} f(\alpha, \, f(\beta, \, \gamma)) = f( f(\alpha, \, \beta), \, \gamma) \quad \text{for every $\alpha, \, \beta, \, \gamma$}. \end{equation*} \end{remark}

\subsection{Local Behavior: Lie Algebras}

In this subsection, we shall consider $N$-dimensional representations $\mathfrak{R} := \{\rho(\alpha), \, V_N \}$ of a Lie group $\G$ of parameter $\alpha$ satisfying
\begin{equation*} \rho(0) = \mathrm{Id}_{N \times N}. \end{equation*}
Therefore, we may expand (using Taylor's formula) the representation $\rho(\alpha)$ for $\alpha$ near the null-vector $\mathbf{0}$. It turns out that
\begin{equation} \label{eq.7.3} \rho(\alpha) = \mathrm{Id}_{N \times N} + \imath \, \alpha_a T^a + \dots \quad \text{where $T^a = - \imath \frac{\partial}{ \partial \alpha_a}  \rho(\alpha)  \, \big|_{\{\alpha\} = 0}$}. \end{equation}
The elements $T^a$ are called \textit{generators} of the group $\G$ in the representation $\mathfrak{R}$. 

\begin{example} The trivial representation clearly gives
\begin{equation*} T^a  = 0 \quad \text{for every $a$}. \end{equation*} \end{example}

The set of generators $\{T^a\}_{a = 1, \, \dots}$ of the group $\G$ associated to the representation $\mathfrak{R}$ satisfies the following properties: \mbox{}
\begin{enumerate}[label=\arabic*)]
\item The set $\{T^a\}_{a = 1, \, \dots}$ form a basis of a vector space $\g = \mathrm{Alg}[\G]$, which means that
\begin{equation*}T^a, \, T^b \in \g \implies c_a T^a + c_b T^b \in \g \quad \text{for every $c_a, \, c_b \in \R$}.  \end{equation*}
\item The set $\{T^a\}_{a = 1, \, \dots}$ is closed under the commutations, that is,
\begin{equation*} [T^a, \, T^b] \in \g \quad \text{for every $a, \, b$}. \end{equation*}
\end{enumerate}
The closure under commutations may be rewritten in a different form by choosing the appropriate basis for the vector space $\g$, that is,
\begin{equation} \label{eq.3} [T^a, \, T^b] := \imath f^{abc} T^c. \end{equation}
The constants $f^{abc}$ are usually referred to as \textit{structure constants}\index{structure constants} of the group $\G$ in the literature. It follows from \eqref{eq.3} that
\begin{equation} \label{eq.3.2}  f^{abc} = - f^{bac}.\end{equation}
The basis $\{T^a\}_{a = 1, \, \dots}$ form the so-called \textit{Lie algebra}\index{Lie algebra} $\g$ of the group $\G$, and it is clearly uniquely characterized by the value of the structure constants.

The representation $\mathfrak{R}$ can be chosen among many, but a convenient choice is to consider the \textit{exponential representation}\index{exponential representation} given by
\begin{equation*} \rho(\alpha) = \mathrm{e}^{\imath \alpha_a T^a} =: \mathrm{e}^{\imath \alpha \cdot T}, \end{equation*}
which can be interpreted as the limit of $k$ iterations of the infinitesimal transformation, obtaining the following expression
\begin{equation*}\mathrm{e}^{\imath \alpha_a T_a} = \lim_{k \to + \infty} \left(1 + \imath \, \frac{\alpha_a T^a}{k} \right)^k \end{equation*}
so that formula \eqref{eq.7.3} makes sense.

We now want to prove the necessity of the condition \eqref{eq.3}, which follows from the associative property of $\G$. If we set $\alpha T := \alpha \cdot T = \alpha_a T^a$, then the property \textbf{(a)} of a Lie group implies that
\begin{equation} \label{eq.2} \mathrm{e}^{\imath \alpha T} \mathrm{e}^{\imath \beta T} = \mathrm{e}^{\imath \delta T}  \end{equation}
for some parameter $\delta$. In particular, it follows from \eqref{eq.2} that
\begin{equation*} \begin{aligned}\imath \delta T & = \log \left(\mathrm{e}^{\imath \alpha T} \mathrm{e}^{\imath \beta T}\right) =
\\[1em] & = \log \left(\mathrm{e}^{\imath \alpha T} \mathrm{e}^{\imath \beta T} \pm \mathrm{Id}_{N \times N} \right) \simeq
\\[1em] & \overset{ \alpha, \, \beta \sim 0}{\simeq} \log(\mathrm{Id}_{N \times N} + K) =
\\[1em] & = K - \frac{1}{2} K^2 + \frac{1}{3} K^3 + \dots,  \end{aligned} \end{equation*}
where $K$ denotes the matrix $\mathrm{e}^{\imath \alpha T} \mathrm{e}^{\imath \beta T} - \mathrm{Id}_{N \times N}$. On the other hand, we have
\begin{equation*} \begin{aligned}K & \simeq (\mathrm{Id}_{N \times N} + \imath \alpha T + \dots) (\mathrm{Id}_{N \times N} + \imath \beta T + \dots) - \mathrm{Id}_{N \times N} =
\\[1em] & = \imath \alpha T + \imath \beta T - (\alpha T)(\beta T) - \frac{1}{2} (\alpha T)^2 - \frac{1}{2} (\beta T)^2 + \dots, \end{aligned} \end{equation*}
which means that
\begin{equation*} \begin{aligned} \imath \delta T & = \imath \alpha T + \imath \beta T + \frac{1}{2} [\beta T, \, \alpha T] + \dots = \\[1em] & =  \imath \alpha T + \imath \beta T - \frac{1}{2} [\alpha T, \, \beta T] + \dots \end{aligned}\end{equation*}
since the quadratic terms $(\alpha T)^2$ and $(\beta T)^2$ vanish. In conclusion, for small parameters $\alpha, \, \beta$ and $\gamma$ it turns out that
\begin{equation*} [\alpha_a T^a, \, \beta_b T^b] = - 2 \imath(\delta_c - \alpha_c - \beta_c)T^c =: \imath \gamma_c T^c, \end{equation*}
and thus
\begin{equation*} \gamma_c = - 2(\delta_c - \alpha_c - \beta_c) = \alpha_a \beta_b f^{abc} \implies [T^a, \, T^b] = \imath f^{abc} \, T^c, \end{equation*}
which justifies the definition \eqref{eq.3}.

\paragraph{N.B.} The Lie algebras are subject to a consistency condition
\begin{equation} \label{jacobi} \left[ [T^a, \, T^b], \, T^c \right] + \left[ [T^b, \, T^c], \, T^a \right] + \left[ [T^c, \, T^a], \, T^b \right] = 0, \end{equation}
known as the \textit{Jacobi identity}.

\subsection{Adjoint Representation}\index{Adjoint Representation}

Let $T^a \in \g$ be a Lie algebra. The relation \eqref{eq.3} implies that
\begin{equation*}\left[ [T^a, \, T^b], \, T^c \right] = \imath f^{abd} \left[T^d, \, T^c \right] = \underbrace{\imath^2}_{= -1} f^{abd}f^{dce} T^e,\end{equation*}
and similarly
\begin{equation*}\left[ [T^b, \, T^c], \, T^a \right] = - f^{bcd}f^{dae} T^e \quad \text{and} \quad \left[ [T^c, \, T^a], \, T^b \right] = - f^{cad}f^{dbe} T^e.\end{equation*}
If we plug these identities into the Jacobi identity \eqref{jacobi}, we find that
\begin{equation} \label{eq.4.1} f^{abd}f^{dce} + f^{bcd}f^{dae} + f^{cad}f^{dbe} = 0 \quad \text{for every $a, \, b, \, c, \, e \in \{1, \, \dots, \, r\}$}.\end{equation}
We now consider the $r$ matrices defined by
\begin{equation*} \left( \mathbb{T}^a \right)_{b, \, c} := \imath f^{bac}, \end{equation*}
and we prove that $\{ \mathbb{T}^a \}_{a = 1, \, \dots, \, r}$ are the generators of the group $\G$ in the representation $\mathfrak{R}^\ast$, which is called \textit{adjoint representation} of $\mathfrak{R}$. Indeed, it follows from the definition and formula \eqref{eq.4.1} that
\begin{equation*} \begin{aligned} \left( \left[ \T^a, \, \T^b \right] \right)_{d, \, e} &= \left(\T^a \T^b \right)_{d, \, e} - \left(\T^b \T^a \right)_{d, \, e} =
\\[1em] & = (\T^a)_{d, \, c} (\T^b)_{c, \, e} - (\T^b)_{d, \, c} (\T^a)_{c, \, e} =
\\[1em] & = - f^{dac} f^{cbe} + f^{dbc} f^{cae} =
\\[1em] & \stackrel{(*)}{=} - f^{dac} f^{cbe} - f^{bdc} f^{cae} =
\\[1em] & \stackrel{(**)}{=} - f^{abc} f^{dce} =
\\[1em] & = \imath f^{abc} (\T^c)_{d, \, e},\end{aligned}\end{equation*}
which is exactly the relation \eqref{eq.3}.

The equality (*) follows immediately from the antisymmetric behavior of $f^{abc}$ with respect to the first two coordinates \eqref{eq.3.2}, while the equality (**) follows from \eqref{eq.4.1}.

\subsection{Examples}
In this brief section, we discuss the main examples proposed in the first chapter (e.g., the Euclidean group, the special unitary group, etc.)

\begin{example}[$\mathrm{SO}(2, \, \R)$] The special orthogonal group on $\R^2$ is given by the elements
\begin{equation*} R(\theta) := \begin{pmatrix} \cos \theta & \sin \theta \\ - \sin \theta & \cos \theta \end{pmatrix}, \end{equation*}
and therefore it is a one-parameter continuous group with $\theta \in [0, \, 2 \pi)$. For $\theta \sim 0$ it turns out that
\begin{equation*} R(\theta) \simeq \mathrm{Id}_{2 \times 2} + \imath \theta \begin{pmatrix} 0 & - \imath \\ \imath & 0\end{pmatrix}, \end{equation*}
which means that the unique generator is given by
\begin{equation*} T = \begin{pmatrix} 0 & - \imath \\ \imath & 0\end{pmatrix}.\end{equation*}
The representation $\rho(\theta) := R(\theta)$ is the fundamental one (i.e., the smallest that is not trivial), and it is easy to prove that
\begin{equation*} \mathrm{e}^{\imath \theta T} = R(\theta) \quad \text{for every $\theta \in [0, \, 2\pi)$}.\end{equation*} \end{example}

\begin{example}[$E_2$] Recall that the $2$-dimensional Euclidean transformations of the form \eqref{eq.1} can be easily rewritten in the following way
\begin{equation*} \begin{pmatrix} x \\ y \\ 1 \end{pmatrix} \longmapsto \left(\begin{array}{@{}c|c@{}}
  R(\theta) &
  \begin{matrix}
  b_1 \\
  b_2
  \end{matrix}
\\ \hline
  \begin{matrix}
  0 & 0
  \end{matrix}
  & 1
\end{array}\right) \begin{pmatrix} x \\ y \\ 1 \end{pmatrix}. \end{equation*}
The generators (see \hyperref[ch:e2]{Chapter \ref{ch:e2}}) are given by
\begin{equation*} \begin{cases} T^1 = - \imath \frac{\partial}{\partial x}, \\[1em] T^2 = - \imath \frac{\partial}{\partial y}, \\[1em] R = - \imath \left( x \frac{\partial}{\partial y} - y \frac{\partial}{\partial x} \right), \end{cases} \end{equation*}
since one can easily check that
\begin{equation*} \begin{aligned} & \mathrm{e}^{\imath b_1 T^1} \begin{pmatrix}x \\ y \end{pmatrix} \simeq (1 + \imath b_1 T^1) \begin{pmatrix}x \\ y \end{pmatrix} = \begin{pmatrix}x + b_1 \\ y \end{pmatrix},
\\[1em] & \mathrm{e}^{\imath b_2 T^2} \begin{pmatrix}x \\ y \end{pmatrix} \simeq (1 + \imath b_2 T^2) \begin{pmatrix}x \\ y \end{pmatrix} = \begin{pmatrix}x \\ y + b_2\end{pmatrix},
\\[1em] & \mathrm{e}^{\imath \theta R} \begin{pmatrix}x \\ y \end{pmatrix} \simeq \begin{pmatrix}x \\ y \end{pmatrix} + \begin{pmatrix} \theta y \\ - \theta x \end{pmatrix}. \end{aligned} \end{equation*}
The commutators between these generators are easy to compute,
\begin{equation*} \begin{aligned} & [T^1, \, T^2] = 0, \\[1em] & [T^1, \, R] = - \imath T^2, \\[1em] & [T^2, \, R] = \imath T^1 \end{aligned} \end{equation*}
and therefore, for any $a \in \{1, \, 2, \, R\}$, we have
\begin{equation*} f^{12a} = 0 \qquad \text{and} \qquad f^{1R2} = - f^{2 R 1} = -1. \end{equation*}
\end{example}

\begin{example}[$\mathrm{SU}(2, \, \C)$] The three generators of the special unitary group in the fundamental representation (=smallest nontrivial) are
\begin{equation*} T^a = \frac{1}{2} \tau^a,\end{equation*}
where $\tau^a$ denotes the $a$th Pauli matrix, that is,
\begin{equation*} \tau^1 = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}, \qquad \tau^2 = \begin{pmatrix} 0 & - \imath \\ \imath & 0 \end{pmatrix}, \qquad \tau^3 = \begin{pmatrix} 1 & 0 \\ 0 & - 1 \end{pmatrix}.\end{equation*}
A straightforward computation proves that $f^{abc}$ is equal to the well-known Levi-Civita tensor\index{Levi-Civita tensor} $\epsilon^{abc}$, that is,
\begin{equation*} f^{abc} = \epsilon^{abc} := \begin{cases} 1 & \text{if $(a b c)$ is an even permutation,} \\ - 1 & \text{if $(a b c)$ is an odd permutation,} \\ 0 & \text{otherwise}. \end{cases}\end{equation*}
\end{example}

\begin{example}[$\mathrm{SU}(N, \, \C)$] The generators of the Lie algebra in the fundamental representation are the $N \times N$ Hermitian matrices with zero trace
\begin{equation*} (T^a)^\dagger = T^a \quad \text{and} \quad \mathrm{Tr}(T^a) = 0 \quad \text{for $a = 1, \, \dots, \, N^2 - 1$}. \end{equation*}
\end{example}

\begin{example}[$\mathrm{SO}(N, \, \R)$] The generators of the Lie algebra in the fundamental  representation are the $N \times N$ antisymmetric matrices
\begin{equation*} (T^a)^T = - T^a \quad \text{for $a = 1, \, \dots, \, \frac{N(N-1)}{2}$.}\end{equation*}
\caution{The Lie group $\mathrm{SO}(3, \, \R)$ is \underline{not} isomorphic to the Lie group $\mathrm{SU}(2, \, \C)$.}The Lie algebra of $\mathrm{SO}(3)$ is isomorphic (=similar behavior near the identity element), as an algebra, to $\mathrm{SU}(2)$, and we denote this with the symbol\footnote{We shall always use the lower case for the Lie algebra associated to a given Lie group that is denoted by a capital symbol.}
\begin{equation*}\mathrm{su}(2) \sim \mathrm{so}(3). \end{equation*}
More precisely, the generators of the fundamental representation of $SO(3, \, \R)$ are
\begin{equation*} T^1 = \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & - \imath \\ 0 & \imath & 0 \end{pmatrix}, \qquad T^2 = \begin{pmatrix} 0 & 0 & \imath \\ 0 & 0 & 0 \\ -\imath & 0 & 0 \end{pmatrix}, \qquad T^3 = \begin{pmatrix} 0 & -\imath & 0 \\ \imath & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix},\end{equation*}
and it is immediate to check that
\begin{equation*} [T^a, \, T^b] = \imath \epsilon^{abc} T^c, \end{equation*}
where $\epsilon^{abc}$ is the Levi-Civita tensor introduced above.
\end{example}

\begin{example}[$\mathrm{SL}(N, \, \C)$] The generators of the Lie algebra in the fundamental representation are the $N \times N$ matrices with zero trace, that is,
\begin{equation*}\mathrm{Tr}(T^a) = 0 \quad \text{for $a = 1, \, \dots, \, N^2 - 1$}.\end{equation*}
\end{example}

\begin{example}[$\mathrm{S}_p(2N, \, \C)$] The generators of the Lie algebra in the fundamental (=smallest nontrivial) representation are the $2N \times 2N$ matrices satisfying the following property
\begin{equation*} (T^a)^\dagger J + T^a J = 0,\end{equation*}
where
\begin{equation*} J =
\left(
\begin{array}{c|c}
0 & \mathrm{Id}_{N \times N} \\
\hline
- \mathrm{Id}_{N \times N} & 0
\end{array}
\right). \end{equation*}
\end{example}

\section{Lie Algebra}

In this section, we focus more on the study of a Lie algebra $\g$ associated to a Lie group $\G$.

\subsection{SubAlgebras}
\index{Lie algebra!subalgebra}

Let $X^a \in \g$ be a Lie algebra, and consider a subset $\h \subset \g$. If $\{ Y^{\dot{a}} \}$ is the subset of the generators of $\g$ which belongs also to $\h$, then
\begin{equation*}\left[ Y^{\dot{a}}, \, Y^{\dot{b}} \right] \in \h \quad \text{for every $\dot{a}$ and $\dot{b}$} \implies \text{$\h$ is a subalgebra of $\g$}. \end{equation*}
Clearly, both $\mathbf{0}$ and $\g$ form trivial subalgebras of any algebra $\g$.

\begin{definition}[Ideal]\index{Lie algebra!abelian invariant subalgebra}\index{Lie algebra!invariant subalgebra} Let $X^a \in \g$ be a Lie algebra, and let $\{ Y^{\dot{a}} \}$ be the subset of the generators which belongs to a subalgebra $\h \subset \g$. If
\begin{equation}  \label{eq.4}\left[ Y^{\dot{a}}, \, X^b \right] = c_{\dot{d}} Y^{\dot{d}} \in \h \end{equation}
for every choice of $\dot{a}$ and $b$, then $\{Y^{\dot{a}} \}$ generate an \textit{invariant subalgebra/ideal} of $\g$. \end{definition}

\begin{definition}[Abelian] Let $X^a \in \g$ be a Lie algebra, and let $\h \subset \g$ be an invariant subalgebra. If
\begin{equation} \label{eq.4.4}  \left[ Y^{\dot{a}}, \, Y^{\dot{b}} \right] = 0 \quad \text{for every $Y^{\dot{a}}, \, Y^{\dot{b}} \in \h$}, \end{equation}
then $\h$ is said to be an \textit{abelian invariant subalgebra} (or an abelian ideal) of $\g$. \end{definition}

\begin{definition}[Simple Algebra] \index{Lie algebra!simple} A Lie algebra $\g$ is \textit{simple} if the only invariant subalgebras are the trivial ones, that is,
\begin{equation*} \text{$\h \subset \g$ invariant subalgebra} \implies \text{$\h = \{\mathbf{0}\}$ or $\h = \g$}.\end{equation*}
\end{definition}

\begin{definition}[Semisimple Algebra] \index{Lie algebra!semisimple} A Lie algebra $\g$ is \textit{semisimple} if no invariant subalgebra is abelian, except for the null one.
\end{definition}

\begin{definition}[Center]\index{Lie algebra!center} Let $\g$ be a Lie algebra. The \textit{center} of $\g$ is the set of all the elements $T^{\dot{a}} \in \g$ that commutes with every other element in $\g$, that is,
\begin{equation*} C(\g) := \left\{ T^{\dot{a}} \in \g \: : \: \text{$[T^{\dot{a}}, \, T^b] = 0$ for every $T^b \in \g$} \right\}. \end{equation*}
\end{definition}

\begin{lemma} Let $\g$ be a Lie algebra, and let $\h \subset \g$ be an invariant subalgebra. Then $\h$ generates the invariant subgroup $\Ha \subset \G$. \end{lemma}

\begin{proof} Let $h = \mathrm{e}^{\imath \alpha_{\dot{a}} Y^{\dot{a}} } \in \Ha$ and let $g = \mathrm{e}^{\imath \beta_b X^b } \in \G$: we need to prove that $g^{-1} h g \in \Ha$. By definition, the conjugate is given by
\begin{equation*} g^{-1} h g = g^{-1} \mathrm{e}^{\imath \alpha_{\dot{a}} Y^{\dot{a}} } g  = \mathrm{e}^{\imath \alpha_{\dot{a}}(g^{-1} Y^{\dot{a}} g)}, \end{equation*}
and thus it is enough to compute $g^{-1} Y^{\dot{a}} g$. Now
\begin{equation*} \begin{aligned} g^{-1} Y^{\dot{a}} g & = \mathrm{e}^{- \imath \beta_b X^b } Y^{\dot{a}} \mathrm{e}^{\imath \beta_b X^b } =
\\[1em] & = \left( 1 - \imath \beta X - \frac{1}{2} (\beta X)^2 + \dots \right) Y^{\dot{a}} \left( 1 + \imath \beta X - \frac{1}{2} (\beta X)^2 + \dots \right) =
\\[1em] & = Y^{\dot{a}} - \imath [\beta X, \, Y^{\dot{a}} ] + \frac{ (-\imath)^2 }{2} [\beta X, \, [\beta X, \, Y^{\dot{a}}]] + \dots + \frac{ (-\imath)^n }{n!} [\beta X, \, [ \dots [\beta X, \, Y^{\dot{a}}] \dots ]] + \dots =
\\[1em] & = \gamma_{\dot{c}} Y^{\dot{c}} \in \h,   \end{aligned} \end{equation*}
as a consequence of formula \eqref{eq.4}. To conclude the proof, it remains to give a formal justification of the last equality. Let us consider the function
\begin{equation*}G(t) := \mathrm{e}^{- \imath t \beta_b X^b} Y^{\dot{a}} \mathrm{e}^{\imath t \beta_b X^b}, \end{equation*}
so that the idea is to compute $G(1)$ by means of the Taylor's formula, that is,
\begin{equation*}G(1) = \sum_{n = 0}^{+ \infty} \frac{t^n}{n!} \, G^{(n)}(0). \end{equation*}
We already know that $G(0) = Y^{\dot{a}}$, and it is easy to prove that
\begin{equation*}G^\prime(t) =- \mathrm{e}^{- \imath t \beta_b X^b} \imath [\beta X, \, Y^{\dot{a}}] \mathrm{e}^{\imath t \beta_b X^b}, \end{equation*}
which means that
\begin{equation*}G^\prime(0) = - \imath [\beta X, \, Y^{\dot{a}}] = - \imath \beta_b [X^b, \, Y^{\dot{a}}], \end{equation*}
and the right-hand side is equal to $c_{\dot{d}} Y^{\dot{d}}$ by definition of invariant subalgebra \eqref{eq.4}. In a similar fashion, we notice that
\begin{equation*}G^{(2)}(t) \, \big|_{t = 0} = \frac{ (-\imath)^2 }{2} [\beta X, \, [\beta X, \, Y^{\dot{a}}]], \end{equation*}
and thus by induction we infer that $g^{-1} h g \in \Ha$.\end{proof}

\begin{corollary} The center of a Lie algebra $\g$ generates the center of the Lie group $\G$. \end{corollary}

\section{Killing Form}

In this section, we introduce a metric $g^{ab}$, also called \textit{killing form}, which gives us a compelling criterion to check whether a given Lie algebra is semisimple or not.

\begin{definition}[Killing Form] Let $\g$ be a Lie algebra. We define a metric by setting \index{killing form} 
\begin{equation} \label{kf} g^{ab} := f^{acd} f^{bdc} \quad \text{for every $a, \, b \in \{1, \, \dots, \, r\}$}, \end{equation}
where $r$ is the group dimension.
\end{definition}

\begin{theorem}[Cartan]\label{thm:cartan} A Lie algebra $\g$ is semisimple if $\mathrm{det} \left| g^{ab} \right|$ is nonzero. \end{theorem}

\begin{proof}We may equivalently prove the negation:
\begin{equation*} \textit{"If $\g$ is not a semisimple Lie algebra, then $\mathrm{det} \left| g^{ab} \right| = 0$."} \end{equation*}
Let $\h \subset \g$ be an invariant abelian subalgebra and $T^{\dot{a}} \in \h$ a generator. We have the identity
\begin{equation*} g^{\dot{a}b} = f^{\dot{a}cd} f^{bdc} \stackrel{(*)}{=} f^{\dot{a}c\dot{d}} f^{b\dot{d}c} \stackrel{(**)}{=} f^{\dot{a}\dot{c}\dot{d}}f^{b\dot{d}\dot{c}} = 0\end{equation*}
as a consequence of the following facts: \mbox{}
\begin{enumerate}[label=\alph*)]
\item The equality (*) is a consequence of \eqref{eq.4} because
\begin{equation*} f^{\dot{a}cd} = [T^{\dot{a}}, \, T^c] = c_{\dot{d}} T^{\dot{d}}. \end{equation*}
\item The equality (**) is also a consequence of \eqref{eq.4} applied to $f^{b\dot{d}c}$.
\item The subalgebra $\h$ is abelian by assumption; hence
\begin{equation*} f^{\dot{a}\dot{c}\dot{d}} T_{\dot{d}} = [T^{\dot{a}}, \, T^{\dot{c}}] = 0 \implies f^{\dot{a}\dot{c}\dot{d}}f^{b\dot{d}\dot{c}} = 0. \end{equation*}
\end{enumerate}
It follows that $g^{\dot{a}b} = 0$ for every $b \in \{1, \, \dots, \, r\}$, and therefore the metric form $g$ has at least a row ($\dot{a}$) that is equal to $(0, \, \dots, \, 0)$. \end{proof}

\subsection{Examples}

We now apply the \textit{Cartan criterion} introduced above to check whether the common algebras we are dealing with in this course are semi-simple or not.

\begin{example}[$\mathrm{su}(2, \, \C) \sim \mathrm{so}(3, \, \R)$]Recall that the structure constants of these Lie algebras are given by the Levi-Civita tensor, that is,
\begin{equation*} f^{abc} = \epsilon^{abc} \quad \text{for every $a, \, b, \, c \in \{1, \, 2, \, 3\}$}. \end{equation*}
It follows that
\begin{equation*} g^{ab} := f^{acd} f^{bdc} = \epsilon^{acd}\epsilon^{bdc} = \begin{cases}-2 & \text{if $a = b$}, \\[0.6em] 0 & \text{if $a \neq b$}, \end{cases} \end{equation*}
and thus the Killing form is given by
\begin{equation*} g= \begin{pmatrix} - 2 & 0 & 0 \\ 0 & - 2& 0 \\ 0 & 0 & -2 \end{pmatrix}.\end{equation*}
In conclusion, since $\mathrm{det}|g^{ab}| \neq 0$, it follows from the \hyperref[thm:cartan]{Cartan's criterion} that the Lie algebra $\mathrm{su}(2, \, \C) \sim \mathrm{so}(3, \, \R)$ is semisimple\caution[b][darkgreen][Note]{Actually, the algebra $\mathrm{su}(2, \, \C) \sim \mathrm{so}(3, \, \R)$ is simple, but we will not prove it here. }.  \end{example}

\begin{example}[$\mathrm{so}(2, \, 1)$] The indefinite special orthogonal group\index{indefinite special orthogonal group}, $\mathrm{SO}(2, 1)$ is the subgroup of $\mathrm{O}(2, 1)$ consisting of all elements with determinant 1. More precisely, given
\begin{equation*} g := \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & - 1 \end{pmatrix}, \end{equation*}
the elements of $\mathrm{SO}(2, 1)$ are the transformations with determinant equal to $1$ that preserves the scalar product $\langle x, \, y \rangle := x^T g y$. The generators\footnote{We shall compute them explicitly later on the course.} of the algebra $\mathrm{so}(2, 1)$ satisfy the following relations
\begin{equation*} \begin{aligned} & [T^1, \, T^2] = \imath T^3, \\[0.8em] & [T^2, \, T^3] = - \imath T^1, \\[0.8em] & [T^3, \, T^1] = \imath T^2, \end{aligned} \end{equation*}
which means that the Killing form is given by
\begin{equation*} g= \begin{pmatrix} - 2 & 0 & 0 \\ 0 & - 2& 0 \\ 0 & 0 & 2 \end{pmatrix}.\end{equation*}
In particular, by \hyperref[thm:cartan]{Cartan's criterion} the algebra $\mathrm{so}(2, \, 1)$ is semisimple.\end{example}

\begin{example}[$E_2$] Recall that the generators of the Lie algebra $\g$ associated to the Euclidean group $E_2$ are given by
\begin{equation*} \begin{cases} T^1 = - \imath \frac{\partial}{\partial x}, \\[1em] T^2 = - \imath \frac{\partial}{\partial y}, \\[1em] R = - \imath \left( x \frac{\partial}{\partial y} - y \frac{\partial}{\partial x} \right), \end{cases} \end{equation*}
which means that the structure constants are
\begin{equation*} f^{12R} = 0, \qquad f^{2R1} = 1, \qquad f^{1R2} =- 1. \end{equation*}
We can easily compute the Killing form from the definition \eqref{kf}, obtaining
\begin{equation*} g^{ab} := f^{acd} f^{bdc} = \begin{pmatrix} - 2 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix} \implies \mathrm{det}|g^{ab}| = 0,\end{equation*}
which means that by \hyperref[thm:cartan]{Cartan's criterion} the algebra associated to $E_2$ is not semisimple. 

More precisely, the reader may check (using the definitions) that $\{T^1, \, T^2\}$ generate an invariant subalgebra $\h \in \g$ that is abelian (see \hyperref[ch:e2]{Chapter \ref{ch:e2}} for a detailed dissertation.)
\end{example}

\section{Casimir Operator}

In mathematics, a \textit{Casimir Operator} is a precise element which lies within the center of a Lie algebra (e.g., the square of the angular momentum modulus in $\mathrm{so}(3, \, \R)$).

Let $\g$ be a \textbf{semisimple} Lie algebra, and let $g^{ab}$ denote its Killing form \eqref{kf}. The matrix $g$ is invertible by Cartan's criterion, and therefore the inverse is well-defined:
\begin{equation*} g_{ab} := (g^{-1})_{ab} \end{equation*}

\begin{definition}\index{Casimir operator} The (quadratic) \textit{Casimir operator} of a semisimple Lie algebra $\g$ is defined by setting
\begin{equation} \label{caso} C := g_{ab}T^aT^b, \end{equation}
where $\{T^a\}$ is the set of generators of $\G$. \end{definition}

\begin{lemma} The Casimir operator $C$ is an element of the center $C(\g)$, that is,
\begin{equation*} [C, \, T^a] = 0 \quad \text{for every $T^a \in \g$}. \end{equation*} \end{lemma}

We also notice that, if we define $c_{abc} := g^{ae} f^{bce}$, then it turns out that $c_{abc} = c_{bca} = c_{cab}$. Moreover, the Casimir operator $C$ takes a constant value in a representation\footnote{We shall see later that this property is a simple consequence of the well-known Schur's Lemma.}, characterizing completely every other representation.

\begin{example}The Casimir operator of the Lie algebra $\mathrm{so}(3, \, \R) \sim \mathrm{su}(2, \, \C)$ is proportional to $T^aT^a$, which means that
\begin{equation*}C \propto (T^1)^2 + (T^2)^2 + (T^3)^2. \end{equation*}
The right-hand side is equal to the modulus squared of the angular momentum.\end{example}