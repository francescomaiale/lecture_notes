\chapter{Baker–Campbell–Hausdorff Formula}

Let $X$ and $Y$ be vector fields. If $[X, \, Y] = 0$, then it is easy to verify that the exponential map of the sum is given by
\[
\e^{tX + sY} = \e^{tX} \e^{sY},
\]
but this is not the case if $X$ and $Y$ do not commute. The main goal of this chapter is to prove the \textbf{Baker–Campbell–Hausdorff formula}, which gives us a way to express
\[
\e^{tX+ sY}
\]
in terms of the so-called elementary commutators. The central role taken on by this formula will be more clear when we will talk about Lie groups and, more specifically, Lie algebras.

\section{Free associative algebra}

Let $R$ be a commutative ring. The free (associative, unital) algebra\index{free algebra} on $n$ variables, say $\{a_1, \, \dots, \, a_n\}$ is the free $R$-module with a basis consisting of all words over the alphabet
\[
\scA := \{ a_1, \, \dots, \, a_n \},
\]
including the empty word, which is the unit of the free algebra. It is easy to see that endowed with the concatenation of words as multiplication, we obtain an $R$-algebra

Let $R := \R$ and consider the {\em associative free algebra generated} generated by two elements, say $x$ and $y$, over $R$. We recall that an element (or word) of length $L$ can be written as
\[
u = x^{i_1} y^{j_1} \dots x^{i_\ell} y^{j_\ell},
\]
where $i_k, \, j_k \geq 0$ and $\sum_{k = 1}^\ell (i_k + j_k) = L$. If $[x, \, y] = 0$, then $L$-words are of the form
\[
u = x^{\ell} y^{L - \ell},
\]
but, in general, we do not expect to be in such a simple situation. It makes sense to introduce the notation $a[x, \, y]$ for the free algebra generated by $x$ and $y$. Recall that
\[
a \llbracket x, \, y \rrbracket
\]
indicates the set of formal power series with elements in $a[x, \, y]$. Namely, $u \in a \llbracket x, \, y \rrbracket$ if
\begin{equation*} u = \sum_{k = 0}^\infty c_k, \end{equation*}
where $c_k$ is a linear combination of words of length $k$. The exponential of $u$,
\[
\e^u = \sum_{k = 0}^\infty \frac{1}{k!} u^k,
\]
is well-defined provided that $c_0 = 0$ (so we can apply Taylor's theorem) so we define 
\[
a_0 \llbracket x, \, y \rrbracket := \{ u \in a_0 \llbracket x, \, y \rrbracket \: : \: c_0 = 0 \}.
\]

\brmk
Let $\cA$ be an associative algebra. The bracket operator
\[
[u, \, v] := uv - vu
\]
satisfies the following properties: \mbox{}
\begin{enumerate}[label={\color{red}\textbf{(\alph*)}}]
\item $[ \cdot, \, \ast ]$ is bilinear;
\item $[ \cdot, \, \ast ]$ is skew-symmetric;
\item $[ \cdot, \, \ast ]$ satisfies the Jacobi identity\index{Jacobi identity}, that is,
\begin{equation}\label{jacobi1000}\left[ [u,\,v], \, w \right] +  \left[ [w,\, u], \, v \right] +  \left[ [v,\,w], \, u \right] = 0. \end{equation}
\end{enumerate}
In particular, any associative algebra $\cA$ endowed with this bracket operator is a Lie algebra\footnote{Recall that a Lie algebra only requires the existence of a bracket operator\index{bracket operator}, but it does not have to be associative. In any case, we say that when $[\cdot, \, \ast] \equiv 0$ the associated Lie algebra is abelian.}. The interested reader can find a more precise definition in \hyperref[chapter:Liegroups]{Chapter \ref{chapter:Liegroups}}, but we still recommend to read it after this one.
\ermk

\section{Baker–Campbell–Hausdorff formula}

Let $\cF$ be the Lie sub-algebra generated by $x$ and $y$ in $a \llbracket x, \, y \rrbracket$. Then $\cF$ is closed under the bracket operator and it is easy to verify that
\[
x, \, y \in \cF, \quad [x, \, y] \in \cF, \quad [[x, \, y], \, x] \in \cF.
\]
One might also check that elements such as $x^2$ or $y^2$ are not in $\cF$ proving that it is not possible to obtain them via the bracket operator starting from $x$ and $y$ only.

\bd
A commutator of the form
\[
\left[ a_1, \, \dots [a_{k-2}, \, [a_{k-1}, \, a_k]] \dots \right]
\]
is called {\em elementary iterated commutator}\index{elementary iterated commutator}.
\ed

\brmk
The Lie sub-algebra $\cF$ is not made up entirely of elementary iterated commutators. For example,
\[
[ [[x, \, y], \, x], \, [x, \, y]] \in \cF
\]
is not a elementary commutator. However, using \eqref{jacobi1000}, one can prove that it can also be written as the sum of elementary commutators.
\ermk

\bpr
The linear space $\cF$ is spanned by $x, \, y$ and elementary commutators.
\epr

As a corollary of this result, we can always write $\cF$ as the sum of linear subspaces in the following form:
\[
\cF = \sum_{k_1 + k_2 \geq 1} \cF^{k_1, \, k_2},
\]
where $(k_1, \, k_2)$, called {\em bidegree}, indicates the number of times $x$ and $y$ appear in the elementary iterated commutator.

\bthm[Baker–Campbell–Hausdorff] \label{thm.bchthm} \index{Baker–Campbell–Hausdorff formula}
Let $x$ and $y$ be as above. Then
\[
\e^{x} \e^{y} = \e^u, 
\]
and we can express $u$ explicitly with the following formula:
\[
u = x + y + \sum_{k_1 + k_2 \geq 1} c_{k_1, \, k_2},
\]
where $c_{k_1, \, k_2}\in \mathcal{F}^{k_1, \, k_2}$ for all $(k_1, \, k_2)$ admissible. In particular, if $X$ and $Y$ are smooth vector fields on $\Omega$ that do not commute, we have that
\begin{equation}\label{bchformula}
\e^{tX} \e^{sY} = \e^{tX + sY + \sum_{k_1 + k_2 \geq 1} c_{k_1, \, k_2}(tX, \, sY)}.
\end{equation}
\ethm

\brmk
There are iterative methods to determine the coefficients $c_{k_1, \, k_2}$, but we usually care only about the abstract formula. In any case, the first two terms - which is always useful to remember - are given by
\[
X + Y + \frac{1}{2}[X, \, Y] + \frac{1}{12} \left( [X, \, [X, \, Y]] - [Y,\, [X, \, Y]] \right).
\]
\ermk

\brmk
The \textsc{BCH} formula allows one to write
\[
\e^{u} \e^{v} = \e^w
\]
even if $u$ and $v$ are elements of $\cF$ rather than $x$ or $y$. Hence $w$ is not, in general, in $\cF$ but rather a formal sum of such elements.
\ermk

\subsection{Consequences of the BCH formula} %% Qui

\begin{proposition} \label{prop.diff.2.1}\mbox{}
\begin{enumerate}[label=\textbf{(\roman*)}]
\item For each $n \geq 1$ there exists a unique decomposition
\begin{equation*} \mathrm{e}^{x+y} = \mathrm{e}^x \mathrm{e}^y \mathrm{e}^{w_2} \dots \mathrm{e}^{w_n} \mathrm{e}^{r_{n+1}}, \end{equation*}
where $w_j \in \mathcal{F}^j$ and $r_{n+1} \in \sum_{k \geq n + 1} \mathcal{F}^k$.
\item If $c_p \in \mathcal{F}^p$, then there exists $q(p) := q > 0$ such that
\begin{equation} \label{eq.g.1} \mathrm{e}^{c_p} = \mathrm{e}^{a_1}\dots \mathrm{e}^{a_q} \mathrm{e}^{r_{p+1}}, \end{equation}
where $a_j \in \{ \pm x, \, \pm y\}$ and $r_{p+1} \in \sum_{k \geq p + 1} \mathcal{F}^k$.
\end{enumerate} \end{proposition}

\begin{proof} We can prove both assertions with $n = 1$, $p = 2$ and then apply the induction principle to conclude that it holds for all $n$ and all $p$. \mbox{}
\begin{enumerate}[label=\textbf{(\roman*)}]
\item Set
\begin{equation*} \star := \mathrm{e}^{-y}\mathrm{e}^{-x}\mathrm{e}^{x + y}, \end{equation*}
and use the \textsc{BCH} formula to rewrite the first two terms as follows:
\begin{equation*} \star = \mathrm{e}^{-(x+y) + r_2(x, \, y)}\mathrm{e}^{x + y}. \end{equation*}
Now use the formula again to obtain the identity
\begin{equation*} \star = \mathrm{e}^{r_2(x, \, y) + \frac{1}{2}[-(x+y) + r_2(x, \, y), \, x + y]} = \mathrm{e}^{\widetilde{r_2}(x, \, y)}, \end{equation*}
and this proves the formula for $n = 1$ since
\begin{equation*} \mathrm{e}^{x+y} = \mathrm{e}^x \mathrm{e}^y \mathrm{e}^{\widetilde{r_2}(x, \, y)}. \end{equation*}
\item Let $p = 2$. Then
\begin{equation*} \begin{aligned} \mathrm{e}^{x}\mathrm{e}^{y}\mathrm{e}^{-x}\mathrm{e}^{-y} & = \mathrm{e}^{x + y + \frac{1}{2}[x, \, y] + r_3(x, \, y)} \mathrm{e}^{-(x + y) + \frac{1}{2}[x, \, y] + r_3(-x, \, -y)} =
\\[1em] & = \mathrm{e}^{[x, \, y] + \frac{1}{2} \left[ x + y + \frac{1}{2}[x, \, y] + r_3(x, \, y), \, -(x + y) + \frac{1}{2}[x, \, y] + r_3(-x, \, -y) \right] + r_3^\prime } =
\\[1em] & = \mathrm{e}^{[x, \, y] + r_3^{\prime \prime}} \stackrel{\star}{=}
\\[1em] & \stackrel{\star}{=} \mathrm{e}^{[x, \, y]} \mathrm{e}^{r_3^{\prime \prime}} \mathrm{e}^{r_2([x, \, y], \, r_3^{\prime \prime})} =
\\[1em] & = \mathrm{e}^{[x, \, y]} \mathrm{e}^{\widetilde{r_3}(x, \, y)},\end{aligned}\end{equation*}
\end{enumerate}
where the identity $\star$ follows from the previous point and all the others from applications of the \textsc{BCH} formula. \end{proof}

% \begin{corollary}  \end{corollary} VEDI BENE

\begin{remark} The formula \eqref{eq.g.1} for $\mathrm{e}^{x+y}$ can be generalized to more than two elements. Namely, one can prove that
\begin{equation} \label{eq.g.1.a} \mathrm{e}^{x_1 + \dots + x_n} = \mathrm{e}^{a_1}\dots \mathrm{e}^{a_q} \mathrm{e}^{r_{p+1}}, \end{equation}
where $a_j \in \{ \pm x_1, \, \dots, \, \pm x_n\}$ and $r_{p+1} \in \sum_{k \geq p + 1} \mathcal{F}^k$ and $\mathcal{F}^k$ is the space of elementary commutators with $n$-degree equal to $k$.\end{remark}

\begin{remark}If $X$ and $Y$ are smooth vector fields, then
\begin{equation*} \mathrm{e}^{t(X + Y)} = \mathrm{e}^{tX} \mathrm{e}^{tY} \mathrm{e}^{\frac{t^2}{2}[X, \, Y]} (1 + \mathcal{O}(t^3)). \end{equation*}
Therefore
\begin{equation*} \mathrm{e}^{-\frac{t^2}{2}[X, \, Y]} \mathrm{e}^{-tY}\mathrm{e}^{-tX}\mathrm{e}^{t(X + Y)} f(x) - f(x) = \mathcal{O}(t^3), \end{equation*}
so we find that the derivatives of first and second order of the left-hand side with respect to $t$ is zero at $t = 0$.
A straightforward computation shows that
\begin{equation*}0 = \frac{\mathrm{d}}{\mathrm{d}t} \, \big|_{t = 0} f(x) = - Yf(x) - Xf(x) + (X + Y)f(x) = 0, \end{equation*}
while, with a little bit more efforts, the second derivative equal to zero gives us
\begin{equation*}0 = \frac{\mathrm{d}}{\mathrm{d}t^2} \, \big|_{t = 0} f(x) = [...]. \end{equation*}
\end{remark}